{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c0d2b8",
   "metadata": {},
   "source": [
    "Have some function $J(w, b)$\n",
    "\n",
    "Want $\\min_{w, b} J(w, b)$\n",
    "\n",
    "Outline:\n",
    "- Start with some $w, b$, (set them to 0)\n",
    "- Keep changing $w, b$ to minimize $J(w, b)$\n",
    "- Until we settle at or near the minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27983bb0",
   "metadata": {},
   "source": [
    "# Gradient Descent Algorithm\n",
    "\n",
    "$$\n",
    "w = w - \\alpha \\frac{\\partial }{\\partial w}J(w, b)\n",
    "$$\n",
    "\n",
    "- Learning rate: $\\alpha$, between 0 and 1\n",
    "- Gradient: $\\frac{\\partial }{\\partial w}J(w, b)$\n",
    "\n",
    "$$\n",
    "b = b - \\alpha \\frac{\\partial }{\\partial b}J(w, b)\n",
    "$$\n",
    "\n",
    "Simultaneously update $w$ and $b$\n",
    "\n",
    "Correct: Simultaneously update\n",
    "\n",
    "$$\n",
    "tmp\\_w = w - \\alpha \\frac{\\partial }{\\partial w}J(w, b)\n",
    "$$\n",
    "\n",
    "$$\n",
    "tmp\\_b = b - \\alpha \\frac{\\partial }{\\partial b}J(w, b)\n",
    "$$\n",
    "\n",
    "$$\n",
    "w = tmp\\_w\n",
    "$$\n",
    "\n",
    "$$\n",
    "b = tmp\\_b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb0d52e",
   "metadata": {},
   "source": [
    "# Learning Rate\n",
    "\n",
    "If $\\alpha$ is too small\n",
    "\n",
    "Gradient descent may be slow\n",
    "\n",
    "If $\\alpha$ is too large\n",
    "\n",
    "Gradient descent may:\n",
    "- Overshoot, never reach the minimum\n",
    "- Fail to converge, diverge\n",
    "\n",
    "If the $w$ in the local minimum, then the $w$ will not change\n",
    "\n",
    "Near a local minimum,\n",
    "- Derivative becomes smaller\n",
    "- Update steps become smaller"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
